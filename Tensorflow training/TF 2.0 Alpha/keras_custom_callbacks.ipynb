{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks are useful to get a view on internal states and statistics of the model \n",
    "# during training.\n",
    "# Defines the Keras model to add callbacks to.\n",
    "def get_model():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Dense(1, activation = 'linear', input_dim = 784))\n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.1), loss='mean_squared_error', metrics=['mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads example MNIST data and pre-process it.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "  def on_train_batch_begin(self, batch, logs=None):\n",
    "    print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
    "\n",
    "  def on_test_batch_begin(self, batch, logs=None):\n",
    "    print('Evaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
    "\n",
    "  def on_test_batch_end(self, batch, logs=None):\n",
    "    print('Evaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: batch 0 begins at 10:39:38.405603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: batch 0 ends at 10:39:38.672845\nTraining: batch 1 begins at 10:39:38.673230\nTraining: batch 1 ends at 10:39:38.720355\nTraining: batch 2 begins at 10:39:38.720838\nTraining: batch 2 ends at 10:39:38.767838\nTraining: batch 3 begins at 10:39:38.768244\nTraining: batch 3 ends at 10:39:38.814460\nTraining: batch 4 begins at 10:39:38.814808\nTraining: batch 4 ends at 10:39:38.862105\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=1,\n",
    "          steps_per_epoch=5,\n",
    "          verbose=0,\n",
    "          callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Users can supply a list of callbacks to the following tf.keras.Model methods:\n",
    "\n",
    "\t- fit(), fit_generator().\n",
    "\t- evaluate(), evaluate_generator().\n",
    "\t- predict(), predict_generator().\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: batch 0 begins at 10:39:41.612639\nEvaluating: batch 0 ends at 10:39:41.680305\nEvaluating: batch 1 begins at 10:39:41.681081\nEvaluating: batch 1 ends at 10:39:41.686469\nEvaluating: batch 2 begins at 10:39:41.686822\nEvaluating: batch 2 ends at 10:39:41.691684\nEvaluating: batch 3 begins at 10:39:41.692047\nEvaluating: batch 3 ends at 10:39:41.697310\nEvaluating: batch 4 begins at 10:39:41.698033\nEvaluating: batch 4 ends at 10:39:41.703055\n"
     ]
    }
   ],
   "source": [
    "_ = model.evaluate(x_test, y_test, batch_size=128, verbose=0, steps=5,\n",
    "          callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In on_(train|test|predict)_batch_begin(self, batch, logs=None), 'logs' is a dict with batch and size available keys, representing the current batch number and the size of the batch.\n",
    "\n",
    "- In on_(train|test|predict)_batch_end(self, batch, logs=None), 'logs' is a dict containing the stateful metrics result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is   27.99.\nFor batch 1, loss is  920.77.\nFor batch 2, loss is   25.12.\nFor batch 3, loss is    8.60.\nFor batch 4, loss is    7.08.\nThe average loss for epoch 0 is  197.91 and mean absolute error is    8.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    6.32.\nFor batch 1, loss is    5.80.\nFor batch 2, loss is    5.44.\nFor batch 3, loss is    5.18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 4, loss is    4.99.\nThe average loss for epoch 1 is    5.55 and mean absolute error is    1.95.\nFor batch 0, loss is    4.85.\nFor batch 1, loss is    4.74.\nFor batch 2, loss is    4.65.\nFor batch 3, loss is    4.58.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 4, loss is    4.51.\nThe average loss for epoch 2 is    4.67 and mean absolute error is    1.75.\n"
     ]
    }
   ],
   "source": [
    "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
    "\n",
    "  def on_test_batch_end(self, batch, logs=None):\n",
    "    print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('The average loss for epoch {} is {:7.2f} and mean absolute error is {:7.2f}.'.format(epoch, logs['loss'], logs['mae']))\n",
    "\n",
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          steps_per_epoch=5,\n",
    "          epochs=3,\n",
    "          verbose=0,\n",
    "          callbacks=[LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    4.21.\nFor batch 1, loss is    4.21.\nFor batch 2, loss is    4.21.\nFor batch 3, loss is    4.21.\nFor batch 4, loss is    4.21.\nFor batch 5, loss is    4.21.\nFor batch 6, loss is    4.21.\nFor batch 7, loss is    4.21.\nFor batch 8, loss is    4.21.\nFor batch 9, loss is    4.21.\nFor batch 10, loss is    4.21.\nFor batch 11, loss is    4.21.\nFor batch 12, loss is    4.21.\nFor batch 13, loss is    4.21.\nFor batch 14, loss is    4.21.\nFor batch 15, loss is    4.21.\nFor batch 16, loss is    4.21.\nFor batch 17, loss is    4.21.\nFor batch 18, loss is    4.21.\nFor batch 19, loss is    4.21.\n"
     ]
    }
   ],
   "source": [
    "_ = model.evaluate(x_test, y_test, batch_size=128, verbose=0, steps=20,\n",
    "          callbacks=[LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EarlyStoppingAtMinLoss(tf.keras.callbacks.Callback):\n",
    "  \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
    "\n",
    "  Arguments:\n",
    "      patience: Number of epochs to wait after min has been hit. After this\n",
    "      number of no improvement, training stops.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, patience=0):\n",
    "    super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "\n",
    "    self.patience = patience\n",
    "\n",
    "    # best_weights to store the weights at which the minimum loss occurs.\n",
    "    self.best_weights = None\n",
    "\n",
    "  def on_train_begin(self, logs=None):\n",
    "    # The number of epoch it has waited when loss is no longer minimum.\n",
    "    self.wait = 0\n",
    "    # The epoch the training stops at.\n",
    "    self.stopped_epoch = 0\n",
    "    # Initialize the best as infinity.\n",
    "    self.best = np.Inf\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    current = logs.get('loss')\n",
    "    if np.less(current, self.best):\n",
    "      self.best = current\n",
    "      self.wait = 0\n",
    "      # Record the best weights if current results is better (less).\n",
    "      self.best_weights = self.model.get_weights()\n",
    "    else:\n",
    "      self.wait += 1\n",
    "      if self.wait >= self.patience:\n",
    "        self.stopped_epoch = epoch\n",
    "        self.model.stop_training = True\n",
    "        print('Restoring model weights from the end of the best epoch.')\n",
    "        self.model.set_weights(self.best_weights)\n",
    "\n",
    "  def on_train_end(self, logs=None):\n",
    "    if self.stopped_epoch > 0:\n",
    "      print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is   34.24.\nFor batch 1, loss is  883.28.\nFor batch 2, loss is   29.83.\nFor batch 3, loss is    9.07.\nFor batch 4, loss is    7.21.\nThe average loss for epoch 0 is  192.73 and mean absolute error is    8.41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    6.37.\nFor batch 1, loss is    5.81.\nFor batch 2, loss is    5.43.\nFor batch 3, loss is    5.16.\nFor batch 4, loss is    4.97.\nThe average loss for epoch 1 is    5.55 and mean absolute error is    1.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    4.82.\nFor batch 1, loss is    4.71.\nFor batch 2, loss is    4.62.\nFor batch 3, loss is    4.54.\nFor batch 4, loss is    4.47.\nThe average loss for epoch 2 is    4.63 and mean absolute error is    1.75.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    4.41.\nFor batch 1, loss is    4.35.\nFor batch 2, loss is    4.30.\nFor batch 3, loss is    4.25.\nFor batch 4, loss is    4.20.\nThe average loss for epoch 3 is    4.30 and mean absolute error is    1.66.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    4.16.\nFor batch 1, loss is    4.13.\nFor batch 2, loss is    4.13.\nFor batch 3, loss is    4.35.\nFor batch 4, loss is    6.08.\nThe average loss for epoch 4 is    4.57 and mean absolute error is    1.69.\nRestoring model weights from the end of the best epoch.\nEpoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          steps_per_epoch=5,\n",
    "          epochs=30,\n",
    "          verbose=0,\n",
    "          callbacks=[LossAndErrorPrintingCallback(), EarlyStoppingAtMinLoss()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keras backend exposes get_value/set_value api which can be used to get/set the variables of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "  \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, schedule):\n",
    "    super(LearningRateScheduler, self).__init__()\n",
    "    self.schedule = schedule\n",
    "\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    if not hasattr(self.model.optimizer, 'lr'):\n",
    "      raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "    # Get the current learning rate from model's optimizer.\n",
    "    lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
    "    # Call schedule function to get the scheduled learning rate.\n",
    "    scheduled_lr = self.schedule(epoch, lr)\n",
    "    # Set the value back to the optimizer before this epoch starts.\n",
    "    tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "    print('\\nEpoch %05d: Learning rate is %6.4f.' % (epoch, scheduled_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00000: Learning rate is 0.1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is   31.62.\nFor batch 1, loss is  905.65.\nFor batch 2, loss is   28.07.\nFor batch 3, loss is    9.50.\nFor batch 4, loss is    7.65.\nThe average loss for epoch 0 is  196.50 and mean absolute error is    8.40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: Learning rate is 0.1000.\nFor batch 0, loss is    6.72.\nFor batch 1, loss is    6.09.\nFor batch 2, loss is    5.65.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 3, loss is    5.34.\nFor batch 4, loss is    5.12.\nThe average loss for epoch 1 is    5.78 and mean absolute error is    2.00.\n\nEpoch 00002: Learning rate is 0.1000.\nFor batch 0, loss is    4.95.\nFor batch 1, loss is    4.82.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 2, loss is    4.72.\nFor batch 3, loss is    4.63.\nFor batch 4, loss is    4.55.\nThe average loss for epoch 2 is    4.73 and mean absolute error is    1.77.\n\nEpoch 00003: Learning rate is 0.0500.\nFor batch 0, loss is    4.48.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 1, loss is    4.45.\nFor batch 2, loss is    4.42.\nFor batch 3, loss is    4.39.\nFor batch 4, loss is    4.35.\nThe average loss for epoch 3 is    4.42 and mean absolute error is    1.69.\n\nEpoch 00004: Learning rate is 0.0500.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    4.32.\nFor batch 1, loss is    4.29.\nFor batch 2, loss is    4.27.\nFor batch 3, loss is    4.24.\nFor batch 4, loss is    4.21.\nThe average loss for epoch 4 is    4.27 and mean absolute error is    1.65.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00005: Learning rate is 0.0500.\nFor batch 0, loss is    4.18.\nFor batch 1, loss is    4.15.\nFor batch 2, loss is    4.13.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 3, loss is    4.10.\nFor batch 4, loss is    4.08.\nThe average loss for epoch 5 is    4.13 and mean absolute error is    1.61.\n\nEpoch 00006: Learning rate is 0.0100.\nFor batch 0, loss is    4.05.\nFor batch 1, loss is    4.05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 2, loss is    4.04.\nFor batch 3, loss is    4.04.\nFor batch 4, loss is    4.03.\nThe average loss for epoch 6 is    4.04 and mean absolute error is    1.59.\n\nEpoch 00007: Learning rate is 0.0100.\nFor batch 0, loss is    4.03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 1, loss is    4.02.\nFor batch 2, loss is    4.02.\nFor batch 3, loss is    4.01.\nFor batch 4, loss is    4.01.\nThe average loss for epoch 7 is    4.02 and mean absolute error is    1.58.\n\nEpoch 00008: Learning rate is 0.0100.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    4.00.\nFor batch 1, loss is    3.99.\nFor batch 2, loss is    3.99.\nFor batch 3, loss is    3.98.\nFor batch 4, loss is    3.97.\nThe average loss for epoch 8 is    3.99 and mean absolute error is    1.57.\n\nEpoch 00009: Learning rate is 0.0050.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    3.97.\nFor batch 1, loss is    3.96.\nFor batch 2, loss is    3.96.\nFor batch 3, loss is    3.95.\nFor batch 4, loss is    3.95.\nThe average loss for epoch 9 is    3.96 and mean absolute error is    1.56.\n\nEpoch 00010: Learning rate is 0.0050.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    3.95.\nFor batch 1, loss is    3.94.\nFor batch 2, loss is    3.94.\nFor batch 3, loss is    3.93.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 4, loss is    3.93.\nThe average loss for epoch 10 is    3.94 and mean absolute error is    1.56.\n\nEpoch 00011: Learning rate is 0.0050.\nFor batch 0, loss is    3.92.\nFor batch 1, loss is    3.92.\nFor batch 2, loss is    3.91.\nFor batch 3, loss is    3.91.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 4, loss is    3.90.\nThe average loss for epoch 11 is    3.91 and mean absolute error is    1.55.\n\nEpoch 00012: Learning rate is 0.0010.\nFor batch 0, loss is    3.90.\nFor batch 1, loss is    3.90.\nFor batch 2, loss is    3.90.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 3, loss is    3.89.\nFor batch 4, loss is    3.89.\nThe average loss for epoch 12 is    3.90 and mean absolute error is    1.54.\n\nEpoch 00013: Learning rate is 0.0010.\nFor batch 0, loss is    3.89.\nFor batch 1, loss is    3.89.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 2, loss is    3.89.\nFor batch 3, loss is    3.89.\nFor batch 4, loss is    3.89.\nThe average loss for epoch 13 is    3.89 and mean absolute error is    1.54.\n\nEpoch 00014: Learning rate is 0.0010.\nFor batch 0, loss is    3.88.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 1, loss is    3.88.\nFor batch 2, loss is    3.88.\nFor batch 3, loss is    3.88.\nFor batch 4, loss is    3.88.\nThe average loss for epoch 14 is    3.88 and mean absolute error is    1.54.\n"
     ]
    }
   ],
   "source": [
    "LR_SCHEDULE = [\n",
    "    # (epoch to start, learning rate) tuples\n",
    "    (3, 0.05), (6, 0.01), (9, 0.005), (12, 0.001)\n",
    "]\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "  \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
    "  if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "    return lr\n",
    "  for i in range(len(LR_SCHEDULE)):\n",
    "    if epoch == LR_SCHEDULE[i][0]:\n",
    "      return LR_SCHEDULE[i][1]\n",
    "  return lr  # If the epoch is none of the ones in LR_SCHEDULE, just return lr.\n",
    "\n",
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          steps_per_epoch=5,\n",
    "          epochs=15,\n",
    "          verbose=0,\n",
    "          callbacks=[LossAndErrorPrintingCallback(), LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applications of callbacks include logging to CSV, saving the model, visualizing on TensorBoard, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}