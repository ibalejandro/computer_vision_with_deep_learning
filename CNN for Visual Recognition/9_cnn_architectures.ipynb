{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Pooling operation preserves the depth of the image representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AlexNet:\n",
    "\t- First use of ReLU, heavy data augmentation (flipping, jittering, cropping, color normalization), ensambling.\n",
    "\t- Network spread across 2 GPUs, half the neurons (feature maps) on each GPU.\n",
    "\t- Connections only with feature maps on same GPU. But also, communication across GPUs in FC layers.\n",
    "\t- First CNN-based winner.\n",
    "\n",
    "- VGG:\n",
    "\t- Deeper networks and smaller filters. Smaller filters have fewer parameters and adds more non-linearities. Stacking them has the same effective receptive field as using a single larger filter.\n",
    "\t- Ensambling for better results.\n",
    "\n",
    "- GoogLeNet (Inception):\n",
    "\t- Deeper networks with computational efficiency, no FC layers.\n",
    "\t- Stacking of inception modules (network within a network).\n",
    "\t- Apply parallel filter operations on an input and concatenate the outputs depth-wise.\n",
    "\t- Bottleneck layers: use 1x1 convolutions to preserve spatial dimension but reduce feature depth (linear combination of your input feature maps).\n",
    "\t- Auxiliary classification outputs (mini-networks with softmax) to inject additional gradient at lower layers. More depth could make the gradient disappear.\n",
    "\n",
    "- ResNet:\n",
    "\t- Very deep networks using residual connections.\n",
    "\t- Copy the learned layers from a shallower model and setting aditional layers to identity mapping.\n",
    "\t- Use layers to fit residual F(x) = H(x) - x instead of H(x) directly.\n",
    "\t- Learn what is it what we need to add/subtract to our input as we move on to the next layer (modifying input in place).\n",
    "\t- Learn the identitiy plus just a little delta.\n",
    "\t- Stack residual blocks.\n",
    "\t- Periodically, double number of filters and downsample spatially using stride 2.\n",
    "\t- Global average pooling layer after last convolutional layer.\n",
    "\t- No FC layers at the end.\n",
    "\t- Bottleneck layers for efficiency.\n",
    "\t- BatchNormalization after every convolutional layer.\n",
    "\t- Weight decay and no dropout.\n",
    "\t- Better than \"human performance\".\n",
    "\n",
    "- Best performing model is Inception-v4 (ResNet + Inception).\n",
    "- ResNet: moderate efficiency and highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4 Bytes per number.\n",
    "\n",
    "- Required memory for forward pass per image = total_num_params_in_cnn * 4.\n",
    "- Required memory for backward pass per image = required memory for forward pass per image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification --> localization --> detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Network in Network: micronetwork within each convolutional layer to compute more abstract features for local patches.\n",
    "\n",
    "- Wide Residual Networks: shallower as ResNet but using more filters per convolutional layer. Increasing width instead of depth is more computationally efficient (parallelizable).\n",
    "\n",
    "- FractalNet: Ultra-deep NN without residuals. Both shallow and deep paths to output.\n",
    "\n",
    "- SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and compression for small size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}